{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b28dea1-cdad-49d1-b63a-1306820233da",
   "metadata": {},
   "source": [
    "# Create PDB frames from structure flipping steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e66fafb5-31cf-4c82-b87d-2b6cb5f4c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from topoly import alexander\n",
    "\n",
    "from foldingdiff import datasets\n",
    "from foldingdiff.angles_and_coords import create_new_chain_nerf\n",
    "from foldingdiff import utils\n",
    "from foldingdiff import modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c236330-5d76-46f5-b472-5b813979fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800671f2-f71d-4dcd-8a26-9c1420e82d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):  \n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        # After convolution and pooling, calculate the number of features for the linear layer\n",
    "        self._to_linear = None\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            self.conv_layer1,\n",
    "            self.relu1,\n",
    "            self.max_pool1,\n",
    "            self.dropout1,\n",
    "            self.conv_layer2,\n",
    "            self.relu2,\n",
    "            self.max_pool2,\n",
    "            self.dropout2,\n",
    "            self.conv_layer3,\n",
    "            self.relu3,\n",
    "            self.max_pool3,\n",
    "            self.dropout3\n",
    "        )\n",
    "        x = torch.randn(512, 1, 128, 6)\n",
    "        self._to_linear = self.convs(x).view(x.size(0), -1).shape[1]\n",
    "                                                                                           \n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_representation):\n",
    "        \n",
    "        # input is 128 x 6\n",
    "        out = self.convs(input_representation)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716df021-5bef-4925-8595-17656df56a1b",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78346735-5d91-40f0-b514-e4849fb684db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(datasets.CathCanonicalAnglesOnlyDataset):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.labels = list(map(lambda x: 0 if x.split('/')[1][0] == 'u' else 1, self.filenames))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return_dict = super().__getitem__(index)\n",
    "        return_dict['angles'] = return_dict['angles'].reshape(1, 128, 6)\n",
    "        label = self.labels[index]\n",
    "        return return_dict, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58624d54-7d15-44f0-b674-2323e16748e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = myDataset(\n",
    "            pdbs='mixed_dataset',\n",
    "            split=None,\n",
    "            pad=128,\n",
    "            min_length=40,\n",
    "            trim_strategy=\"randomcrop\",\n",
    "            zero_center=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eaa22f0-1355-42ec-be1f-4b66251f3079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 395\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "valid_size = int(0.1 * len(dataset))  # 10% for validation\n",
    "test_size = len(dataset) - train_size - valid_size # 10% for testing\n",
    "\n",
    "print(f\"Test set size: {test_size}\")\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78119b53-d620-4b96-b484-1f023cbbbb88",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70a72649-1734-4450-83a0-1bc4a2c74f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv_layer1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (conv_layer2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (conv_layer3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2176, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = torch.load('../models/CNN_model_mixed_dataset.pt', weights_only=False)\n",
    "simple_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8678e9c-0dfd-413e-8454-49cd652bb315",
   "metadata": {},
   "source": "## Flip the structure and save the frame"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f817cca4-891c-4a93-ae7d-17a83bb37da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative process to modify the input\n",
    "def guide_structure(input_structure, prefix, target_label, length, steps, lr, verbose=False):\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam([input_structure], lr=lr)\n",
    "    \n",
    "    for iteration in range(steps):\n",
    "        inner_to_structure(input_structure.detach().to('cpu')[0][0], length, f\"{prefix}{iteration}.pdb\")    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = simple_model(input_structure)\n",
    "\n",
    "        # Compute the loss (maximize the prediction towards the target label)\n",
    "        loss = loss_fn(output, target_label)\n",
    "\n",
    "        # Backward pass and update the input structure\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            angular_idx = np.where(dataset.feature_is_angular['angles'])[0]\n",
    "            # Copy the input structure to avoid in-place modification\n",
    "            modified_structure = input_structure.clone()\n",
    "            for s in modified_structure:\n",
    "                s[..., angular_idx] = utils.modulo_with_wrapped_range(\n",
    "                    s[..., angular_idx], range_min=-np.pi, range_max=np.pi\n",
    "                )\n",
    "            # Update the input structure with the modified one\n",
    "            input_structure.copy_(modified_structure)\n",
    "        \n",
    "        # Print the progress\n",
    "        if iteration % 100 == 0 and verbose:\n",
    "            print(f\"Iteration {iteration}: Loss = {loss.item()}, Prediction = {output.item()}\")\n",
    "\n",
    "    inner_to_structure(input_structure.detach().to('cpu')[0][0], length, f\"{prefix}{steps}.pdb\")\n",
    "    return input_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6218fc9-7fea-48ee-b9ab-e9a37726c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_to_structure(sample, length, name, verbose=False, knot=False):\n",
    "    retval = [s + dataset.get_masked_means() for s in sample]\n",
    "    # Because shifting may have caused us to go across the circle boundary, re-wrap\n",
    "    angular_idx = np.where(dataset.feature_is_angular['angles'])[0]\n",
    "    for s in retval:\n",
    "        s[..., angular_idx] = utils.modulo_with_wrapped_range(\n",
    "                    s[..., angular_idx], range_min=-np.pi, range_max=np.pi\n",
    "                )\n",
    "    df = pd.DataFrame(retval, columns=['phi', 'psi', 'omega', 'tau', 'CA:C:1N', 'C:1N:1CA']).astype(\"float\")[:int(length)]\n",
    "\n",
    "    create_new_chain_nerf(name, df)\n",
    "    \n",
    "    if knot:\n",
    "        knots = alexander(name, tries=70) # TODO modified from 100\n",
    "    \n",
    "        if verbose:\n",
    "            print('Knotting status: ', knots)\n",
    "    \n",
    "        if ('0_1' in knots.keys() and knots['0_1'] > 0.5):\n",
    "            return False\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fc8fba4-8042-4197-bb05-a60b5ba5291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_structure(input_sample, length, orig_label, iterations, lr, debug=False):\n",
    "        \n",
    "    sample = torch.clone(input_sample).unsqueeze(0).to(DEVICE)\n",
    "    orig_prediction = simple_model(sample)\n",
    "        \n",
    "    sample.requires_grad = True\n",
    "        \n",
    "    target = torch.tensor([[1.0 - orig_label]], device=DEVICE)\n",
    "            \n",
    "    new_sample = guide_structure(sample, \"pdbs/timestep_\", target, length, iterations, lr, verbose=debug)\n",
    "    res = inner_to_structure(new_sample.detach().to('cpu')[0][0], length, 'tmp/fliped.pdb', verbose=debug, knot=True)    \n",
    "        \n",
    "    if debug and ((res and (orig_label == 0)) or (not res and (orig_label == 1))):\n",
    "            print(f\"Prediction of original input = {orig_prediction}\")\n",
    "            print(f\"Original label: {orig_label}\")\n",
    "            print(f\"Prediction of new input = {simple_model(new_sample)}\")\n",
    "            print(f\"Target label: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa972aad-ba3b-41f5-ae00-8a43882cb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = next(iter(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d42ffab-5c5a-4865-b552-aea4497c1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 2.8862407207489014, Prediction = 0.055785536766052246\n",
      "Iteration 100: Loss = 1.0499870777130127, Prediction = 0.34994229674339294\n",
      "Knotting status:  {'4_1': 0.7428571428571429, '0_1': 0.21428571428571427}\n",
      "Prediction of original input = tensor([[0.0558]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "Original label: 0\n",
      "Prediction of new input = tensor([[0.6331]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "Target label: tensor([[1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "flip_structure(test_features['angles'][i], test_features['lengths'][i], test_labels[i], 200, 0.001, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1de762-a876-4655-b2f3-322af1a5d9f1",
   "metadata": {},
   "source": [
    "movie created from test sample #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117782f4-e6d9-4ea2-9287-f0fad3cd9ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:foldingdiff2]",
   "language": "python",
   "name": "conda-env-foldingdiff2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
