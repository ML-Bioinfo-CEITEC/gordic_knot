{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc473d9-9a2b-4aa9-8101-8beca68a51f0",
   "metadata": {},
   "source": [
    "# Guide the structure towards knot while doing diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb802454-0d2a-44bc-a94f-902c8790f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from topoly import alexander\n",
    "\n",
    "from typing import *\n",
    "\n",
    "from foldingdiff import sampling\n",
    "from foldingdiff import modelling\n",
    "from foldingdiff import datasets\n",
    "from foldingdiff import utils\n",
    "from foldingdiff.angles_and_coords import create_new_chain_nerf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0af8b-b857-4d88-9406-be46af94a334",
   "metadata": {},
   "source": [
    "## Prepare original training dataset\n",
    "\n",
    "The dataset (folder with the pdb files, starting with 'u' for unknotted and 'k' for knotted) is needed to properly sample the initial noise and then to be able to reconstruct PDB from the inner model representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549230d3-ab91-4bde-ac4f-d934414377d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mixed_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98715876-c257-41ed-ae2a-3beecd3314ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(datasets.CathCanonicalAnglesOnlyDataset):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.labels = list(map(lambda x: 0 if x.split('/')[1][0] == 'u' else 1, self.filenames))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return_dict = super().__getitem__(index)\n",
    "        return_dict['angles'] = return_dict['angles'].reshape(1, 128, 6)\n",
    "        label = self.labels[index]\n",
    "        return return_dict, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4abe71-b062-40b7-b2af-4c0f664b4ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Found 3937 PDB files in mixed_dataset\n",
      "INFO:root:Loading cached full dataset from /home/jovyan/Aknots/Diffusion/foldingdiff/foldingdiff/cache_canonical_structures_mixed_dataset_0fc317992ef2176584cce17d8b0cb0b5.pkl\n",
      "INFO:root:Hash matches between codebase and cached values!\n",
      "INFO:root:Removing structures shorter than 40 residues excludes 0/3936 --> 3936 sequences\n",
      "INFO:root:Offsetting features ['phi', 'psi', 'omega', 'tau', 'CA:C:1N', 'C:1N:1CA'] by means [ 1.32475     1.4534563   1.5235982  -1.4041979   0.09982978  3.1017764\n",
      "  1.9426514   2.0457344   2.1426508 ]\n",
      "INFO:root:Length of angles: 70-128, mean 105.02540650406505\n",
      "INFO:root:CATH canonical angles only dataset with ['phi', 'psi', 'omega', 'tau', 'CA:C:1N', 'C:1N:1CA'] (subset idx [3, 4, 5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "clean_dataset = myDataset(\n",
    "            pdbs=DATASET,\n",
    "            split=None,\n",
    "            pad=128,\n",
    "            min_length=40,\n",
    "            trim_strategy=\"randomcrop\",\n",
    "            zero_center=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514c15c-7d5c-43f9-9e72-5490cb9fa04f",
   "metadata": {},
   "source": [
    "make from the clean dataset instance of noised dataset to be able to sample noise and do the diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230d06d3-56b5-409d-acee-baf06c78b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Getting linear variance schedule with 250 timesteps\n"
     ]
    }
   ],
   "source": [
    "noised_dataset = datasets.NoisedAnglesDataset(clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2a1cc-fea0-4f9b-871f-dfa7efdf3f6b",
   "metadata": {},
   "source": [
    "## Prepare flipping model\n",
    "\n",
    "Load the classifier recognizing knots x unknots.\n",
    "\n",
    "I tried to train two different architectures - tiny dense model (SimpleClassifier) and a simple CNN (SimpleCNN). \n",
    "\n",
    "It's possible to replace this part with arbitrary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd21fe1-5244-49ac-b192-ede8b92a9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):  \n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=(2, 2))\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.max_pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        # After convolution and pooling, calculate the number of features for the linear layer\n",
    "        self._to_linear = None\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            self.conv_layer1,\n",
    "            self.relu1,\n",
    "            self.max_pool1,\n",
    "            self.dropout1,\n",
    "            self.conv_layer2,\n",
    "            self.relu2,\n",
    "            self.max_pool2,\n",
    "            self.dropout2,\n",
    "            self.conv_layer3,\n",
    "            self.relu3,\n",
    "            self.max_pool3,\n",
    "            self.dropout3\n",
    "        )\n",
    "        x = torch.randn(512, 1, 128, 6)\n",
    "        self._to_linear = self.convs(x).view(x.size(0), -1).shape[1]\n",
    "                                                                                           \n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_representation):\n",
    "        \n",
    "        # input is 128 x 6\n",
    "        out = self.convs(input_representation)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409c8544-1908-4286-917d-b2a1cd9a6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):  \n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(64)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(384, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(384, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_representation):\n",
    "        \n",
    "        # Pool the input\n",
    "        pooled_output = self.pooling(input_representation.transpose(1, 2))\n",
    "        \n",
    "        # Flatten the pooled output\n",
    "        flattened_output = pooled_output.reshape(pooled_output.size(0), -1)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(flattened_output)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fbe78-d97b-4dfc-99e4-6f340acf0a3d",
   "metadata": {},
   "source": [
    "Choose the model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11de1b5-6da1-484b-b47b-30c90b6fc1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv_layer1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (conv_layer2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model = torch.load('CNN_model_mixed_dataset.pt', weights_only=False)\n",
    "classification_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d35e4-a676-4719-b687-cc557dcb50be",
   "metadata": {},
   "source": [
    "!!\n",
    "\n",
    "I was stupid and made CNN and dense model with different input dimensions (CNN has one dimension extra).\n",
    "\n",
    "To properly connect the pipeline, please flip the bool according the used model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2eb95b6-a1b6-449c-82ae-e1c88ba86918",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07024011-c2ea-432d-b4d2-319b8b5d9c5f",
   "metadata": {},
   "source": [
    "## Prepare diffusion model\n",
    "\n",
    "Load the original foldingiff model from paper to make the diffusion steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a61785-2b39-4598-a767-e528a51169d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5e524d273747289adbcb56c5e3a7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Auto constructed ft_is_angular: [True, True, True, True, True, True]\n",
      "INFO:root:Found 1 checkpoints\n",
      "INFO:root:Loading weights from /home/jovyan/.cache/huggingface/hub/models--wukevin--foldingdiff_cath/snapshots/98d77b1e68468db5ca03cdba1c0a90f2a2a33edc/models/best_by_valid/epoch=1488-step=565820.ckpt\n",
      "/home/jovyan/my-conda-envs/foldingdiff2/lib/python3.8/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.6.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/huggingface/hub/models--wukevin--foldingdiff_cath/snapshots/98d77b1e68468db5ca03cdba1c0a90f2a2a33edc/models/best_by_valid/epoch=1488-step=565820.ckpt`\n",
      "Using time embedding: GaussianFourierProjection()\n",
      "INFO:root:Mapping loss smooth_l1 to list of losses corresponding to angular [True, True, True, True, True, True]\n",
      "Using loss: [functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793), functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793), functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793), functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793), functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793), functools.partial(<function radian_smooth_l1_loss at 0x7f4b081a6310>, beta=0.3141592653589793)]\n"
     ]
    }
   ],
   "source": [
    "diffusion_model = modelling.BertForDiffusion.from_dir(snapshot_download(\"wukevin/foldingdiff_cath\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395627d-6c6f-4fe8-9d2b-bb4e1747453a",
   "metadata": {},
   "source": [
    "Rewrite the sampling logic a bit to be able to sample different timesteps and just one structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff916d3-ff20-41a8-9e70-70a19bbf1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample(\n",
    "    model: nn.Module,\n",
    "    noise,\n",
    "    train_dset: datasets.NoisedAnglesDataset,\n",
    "    length: int,\n",
    "    timesteps: int,\n",
    "    feature_key: str = \"angles\",\n",
    "    disable_pbar: bool = False,\n",
    "    trim_to_length: bool = True,  # Trim padding regions to reduce memory\n",
    "):\n",
    "\n",
    "    # Produces (timesteps, batch_size, seq_len, n_ft)\n",
    "    sampled = sampling.p_sample_loop(\n",
    "        model=model,\n",
    "        lengths=[length],\n",
    "        noise=noise,\n",
    "        timesteps=timesteps,\n",
    "        betas=train_dset.alpha_beta_terms[\"betas\"],\n",
    "        is_angle=train_dset.feature_is_angular[feature_key],\n",
    "        disable_pbar=disable_pbar,\n",
    "    )\n",
    "    \n",
    "    # Gets to size (timesteps, seq_len, n_ft)\n",
    "    trimmed_sampled = sampled[-1, :, :length, :]\n",
    "    \n",
    "    return trimmed_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2760f-1536-4643-ba9d-78c4bf89e49a",
   "metadata": {},
   "source": [
    "## Guide the structure\n",
    "\n",
    "The logic to take the structure and guide it towards knotting using the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f817cca4-891c-4a93-ae7d-17a83bb37da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide_structure(input_structure, target_label, steps, lr, verbose=False):\n",
    "    # Iterative process to modify the input structure towards target label\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = optim.Adam([input_structure], lr=lr)\n",
    "    \n",
    "    for iteration in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = classification_model(input_structure)\n",
    "\n",
    "        # Compute the loss (maximize the prediction towards the target label)\n",
    "        loss = loss_fn(output, target_label)\n",
    "\n",
    "        # Backward pass and update the input structure\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            angular_idx = np.where(clean_dataset.feature_is_angular['angles'])[0]\n",
    "            # Copy the input structure to avoid in-place modification\n",
    "            modified_structure = input_structure.clone()\n",
    "            for s in modified_structure:\n",
    "                s[..., angular_idx] = utils.modulo_with_wrapped_range(\n",
    "                    s[..., angular_idx], range_min=-np.pi, range_max=np.pi\n",
    "                )\n",
    "            # Update the input structure with the modified one\n",
    "            input_structure.copy_(modified_structure)\n",
    "        \n",
    "        # Print the progress\n",
    "        if iteration % 100 == 0 and verbose:\n",
    "            print(f\"Iteration {iteration}: Loss = {loss.item()}, Prediction = {output.item()}\")\n",
    "    return input_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6218fc9-7fea-48ee-b9ab-e9a37726c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_to_structure(sample, length, name, verbose=False, knot=False):\n",
    "    # reconstruct PDB file from the inner representation\n",
    "    \n",
    "    retval = [s + clean_dataset.get_masked_means() for s in sample]\n",
    "    # Because shifting may have caused us to go across the circle boundary, re-wrap\n",
    "    angular_idx = np.where(clean_dataset.feature_is_angular['angles'])[0]\n",
    "    for s in retval:\n",
    "        s[..., angular_idx] = utils.modulo_with_wrapped_range(\n",
    "                    s[..., angular_idx], range_min=-np.pi, range_max=np.pi\n",
    "                )\n",
    "    df = pd.DataFrame(retval, columns=['phi', 'psi', 'omega', 'tau', 'CA:C:1N', 'C:1N:1CA']).astype(\"float\")[:int(length)]\n",
    "\n",
    "    create_new_chain_nerf(name, df)\n",
    "    \n",
    "    if knot:\n",
    "        knots = alexander(name, tries=70) # TODO modified from 100\n",
    "    \n",
    "        if verbose:\n",
    "            print('Knotting status: ', knots)\n",
    "    \n",
    "        if ('0_1' in knots.keys() and knots['0_1'] > 0.5):\n",
    "            return False\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc8fba4-8042-4197-bb05-a60b5ba5291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_structure(input_sample, target_label, iterations, lr, debug=False):\n",
    "    # full logic to guide the structure\n",
    "        \n",
    "    sample = torch.clone(input_sample).unsqueeze(0).to('cuda')\n",
    "    orig_prediction = classification_model(sample)\n",
    "        \n",
    "    sample.requires_grad = True\n",
    "        \n",
    "    target_label = torch.tensor([[target_label]], device='cuda')\n",
    "            \n",
    "    new_sample = guide_structure(sample, target_label, iterations, lr, verbose=False)\n",
    "        \n",
    "    if debug:\n",
    "            print(f\"Prediction of original input = {orig_prediction.item()}\")\n",
    "            print(f\"Prediction of new input = {classification_model(new_sample).item()}\")\n",
    "    \n",
    "    new_sample = new_sample.detach().to('cpu')[0]\n",
    "    \n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b30ea2-701f-4f9e-a4b8-63745845636d",
   "metadata": {},
   "source": [
    "## Make the flipping loop\n",
    "\n",
    "Unite the diffusion with guiding structure towards knotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec0a5b3-cd7d-4a55-995a-8c46dfcb6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_with_diffusion(timesteps, debug=False):\n",
    "\n",
    "    length = 128 # TODO make possible different lengths\n",
    "    \n",
    "    # Sample noise\n",
    "    noise = noised_dataset.sample_noise(torch.zeros((1, noised_dataset.pad, diffusion_model.n_inputs), dtype=torch.float32))\n",
    "\n",
    "    # do diffusion and then guide towards knot\n",
    "    for t in range(timesteps, 0, -1):\n",
    "        print(f\"-------Starting step {t}-------\")\n",
    "        print(\"--Running diffusion step--\")\n",
    "        s = my_sample(diffusion_model, noise, noised_dataset, length=length, timesteps=t)\n",
    "        inner_to_structure(s.detach()[0], length, f'tmp/diffused_{2*(timesteps - t)}.pdb', verbose=debug, knot=False)\n",
    "        print(\"--Flipping structure--\")\n",
    "\n",
    "        if CNN_model:\n",
    "            noise = flip_structure(s, 1.0, 50, 0.001, debug).unsqueeze(0)[0] # TODO maybe different steps, lr?\n",
    "            inner_to_structure(noise.detach()[0], length, f'tmp/diffused_{2*(timesteps - t) + 1}.pdb', verbose=debug, knot=debug)\n",
    "        else:\n",
    "            noise = flip_structure(s[0], 1.0, 50, 0.001, debug).unsqueeze(0) # TODO maybe different steps, lr?\n",
    "            inner_to_structure(noise.detach()[0], length, f'tmp/diffused_{2*(timesteps - t) + 1}.pdb', verbose=debug, knot=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143226fa-a8cd-445f-9cea-2ba32bf28254",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_with_diffusion(250, debug=True) # 250 is default timesteps in the foldingdiff model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89de658-ecab-4da3-a86d-4bc99ac47f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:foldingdiff2]",
   "language": "python",
   "name": "conda-env-foldingdiff2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
